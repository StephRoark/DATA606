---
title: "Data 606 FinalProject"
author: "Stephanie Roark"
date: "12/12/2018"
output: html_document
---

```{r  global_options, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, eval=TRUE, warning=FALSE, message=FALSE)
```

## Part 1 - Introduction

Breast cancer is one of the most dreaded and deadly cancer diagnosis that a woman can receive. For women in the U.S., breast cancer death rates are higher than those for any other cancer, besides lung cancer. Many institutions have dedicated years of research into improving the survival chances of breast cancer patients and there has been a measure of improvement in the new incidence rates since 2000. Treatment advances, earlier detection through screening, and increased awareness are all key factors in surviving breast cancer and the emergence of machine learning in medical research is an important step in detecting and predicting malignant tumors.

Each year it is estimated that over 252,710 US women will be diagnosed with breast cancer. About 1 in 8 US women will develop invasive breast cancer over the course of her lifetime. Invasive cancer, or Stage-4 breast cancer, is also called metastatic breast cancer. Metastasis happens when cancer cells migrate from the breast elsewhere in the body, triggering cancerous growth and is terminal meaning there is no cure. More than 40,000 US women a year die from metastatic breast cancer and that number has not changed since 1970. Research enabling earlier detection of malignancy is imperative to the survival of women diagnosed with breast cancer.

Tests such as MRI, mammogram, ultrasound and biopsy are commonly used to diagnose breast cancer. Dr. William H. Wolberg, a physician at the University Of Wisconsin Hospital at Madison, created a dataset using Fine Needle Aspiration biopsies to collect samples from patients with solid breast masses and a computer vision approach known as "snakes" to compute values for each of ten characteristics of each nuclei, measuring size, shape and texture. The mean, standard error and extreme values of these features are computed, resulting in a total of 30 nuclear features for each sample.

Using this dataset we can examine the observations of the biospies and investigate whether there are any variables or any combination of the variables which are predictors for a malignant or benign diagnosis.

## Part 2 - Data

```{r data, include=FALSE}
library(MASS)
library(psych)
library(ggplot2)
library(corrplot)
library(bestglm)
library(caret)
library(rsq)
library(tidyverse)
library(dplyr)
# docs at https://cran.r-project.org/web/packages/glmulti/glmulti.pdf
library(glmulti)
library(rJava)

bc_data_all <- read.csv("wisc_bc_data.csv")
###########################
## 85% of the sample size
smp_size <- floor(0.85 * nrow(bc_data_all))

## set the seed to make your partition reproducible
set.seed(42)
train_ind <- sample(seq_len(nrow(bc_data_all)), size = smp_size)

bc_data <- bc_data_all[train_ind, ]
bc_data_test <- bc_data_all[-train_ind, ]

#look at the structure of the data
str(bc_data)
``` 

###Data collection: 

The features in this dataset characterise cell nucleus properties and were generated from image analysis of fine needle aspirates (FNA) of breast masses. They describe characteristics of the cell nuclei present in the image. Dr. William H. Wolberg collected samples from `r nrow(bc_data_all)` patients with solid breast masses and computed values for each of ten characteristics of each nuclei, measuring size, shape and texture including the mean, standard error and extreme values of these features.

###Cases: 

Each case represents an individual sample or observation of tissue taken from a biopsy of a breast mass. There `r nrow(bc_data_all)` observations in the given dataset. 

###Variables: 

####Dependent Variable

The response variable is the diagnosis which is a qualitative binary categorical variable of either benign or malignant.

####Independent Variables

There are 30 independent variables which are quantitative. The variables are all aspects of the tissue samples and include the mean, standard error and worst case for each variable.

Ten real-valued features are computed for each cell nucleus: 

a) radius (mean of distances from center to points on the perimeter) 
b) texture (standard deviation of gray-scale values) 
c) perimeter 
d) area 
e) smoothness (local variation in radius lengths) 
f) compactness (perimeter^2 / area - 1.0) 
g) concavity (severity of concave portions of the contour) 
h) concave points (number of concave portions of the contour) 
i) symmetry 
j) fractal dimension ("coastline approximation" - 1)

All feature values are recoded with four significant digits. There are no missing data.

The class distribution of the data are 357 benign and 212 malignant observations. 

###Type of study: 

This study is an observational study of the biopsied breast tissue mass. The samples were taken as a result of mass detection and not as a part of an experimental study. They were collected as part of a medicial procedure conducted to examine the breast mass tissue in an attempt to diagnos the mass as benign or malignant. The samples are independent of each other. 

###Scope of inference - generalizability: 

The population of interest are people who have detected breast mass and receive treatment for diagnosis. The study is a cross-sectional study (also known as a cross-sectional analysis, transverse study, prevalence study) which is a type of observational study that analyzes data from a population, or a representative subset, at a specific point in time—that is, cross-sectional data. 

A cross-sectional study should be representative of the population if generalizations from the findings are to have any validity. The sample size should be sufficiently large enough to estimate the prevalence of the conditions of interest with adequate precision. 

Non-response, or lack of voluntary subject participation, is a particular problem affecting cross-sectional studies and can result in bias of the measures of outcome. This is a particular problem when the characteristics of non-responders differ from responders.

###Scope of inference - causality: 
No, these data be used to establish causal links between the variables of interest because of the type of study, but the findings can be used to describe the cause of the disease within the population.

## Part 3 - Exploratory Data Analysis

Perform relevant descriptive statistics, including summary statistics and visualization of the data. Also address what the exploratory data analysis suggests about your research question.

```{r summary, include=FALSE}
#check for missing values and summary statistics
summary(bc_data)

describe(bc_data %>% select(-id, -diagnosis))
#how many benign and malignant observations
#table(bc_data$diagnosis)
```

####Boxplots of the 30 Variables vs. Diagnosis:

```{r plots}
bc_data_tall <- bc_data %>% select(-id) %>%
 gather("measurement", "value", -diagnosis)
 

bc_data_tall %>% ggplot(aes(diagnosis, value, color=diagnosis)) +
 geom_boxplot() +
 facet_wrap(~measurement, scales="free_y") +
 theme_minimal() +
 scale_color_manual(labels = c("Begnign", "Malignant"), values = c("blue", "red"))

```

There are no missing values. For some variables, there are clear differences between the distributions of the malignant and benign. There are no obvious outliers.

## Part 4 - Inference

Logistic Regression is used for modeling when there is a categorical response variable with two levels or in other words when the dependent variable is binary.  Like all regression analyses, the logistic regression is a predictive analysis.  Logistic regression is used to describe data and to explain the relationship between one dependent binary variable and one or more nominal, ordinal, interval or ratio-level independent variables.
Logistic regression is a type of Generalized Linear Model.

####Check Conditions 

Conditions for Logistic Regression:

 - Each predictor is linearly related to the logit(pi) if all other predictors are held constant.
See below for linearity test.
 - Each outcome Yi is independent of the other outcomes.
The samples are all taken independently of each other and therefore the data are independent.


###Theoretical Inference - 

####Hypothesis Test and Confidence Intervals

Our null hypothesis is that none of the variables are good predictors for the diagnosis. The alternate hypothesis is that there are specific variables or a combination of variables that are good predictors for the diagnosis. We can write our hypothesis in equation form:

H0 = No variables (individually or in combination) are good predictors for benign or malignant diagnosis.

H1 = There is a specific variable or combination of variables which are good predictors for benign or malignant diagnosis.


```{r glm,include=FALSE}

bc_data_no_id <- bc_data %>% select(-id)
#this model doesn't do a great job of eliminating variables, 24 left, but has a good AIC
bc_model_AIC <- glm(diagnosis ~ ., data = bc_data_no_id, 
                family=binomial, control = list(maxit = 100))

bc_mode.step <- stepAIC(bc_model_AIC, direction = "both")
bc_mode.step$anova
```

###GLM for all Variables

Generalized linear models (GLMs) are an extension of linear models to model non-normal response variables.
Logistic regression is for binary response variables, where there are two possible outcomes.

####Plot of the residuals for the GLM Model with all Variables

```{r glm all}
plot(bc_mode.step)
summary(bc_mode.step)
#plot the deviance residuals of the step glm model
plot(residuals(bc_mode.step))
```

We can see in this plot of the deviation residuals that the model with all variables is too good of a fit and is possibly overfitting the data.


```{r AIC compare, include=FALSE}
bc_model_step1 <- glm(diagnosis ~ radius_mean,
                      data = bc_data, family=binomial(link="logit"),
                      control = list(maxit = 50))
summary(bc_model_step1)

bc_model_step2 <- glm(diagnosis ~ texture_mean,
                      data = bc_data, family=binomial(link="logit"),
                      control = list(maxit = 50))
summary(bc_model_step2) 

bc_model_step3 <- glm(diagnosis ~ perimeter_mean,
                      data = bc_data, family=binomial(link="logit"),
                      control = list(maxit = 50))
summary(bc_model_step3) 

bc_model_step4 <- glm(diagnosis ~ area_mean,
                      data = bc_data, family=binomial(link="logit"),
                      control = list(maxit = 50))
summary(bc_model_step4) 

bc_model_step5 <- glm(diagnosis ~ smoothness_mean,
                      data = bc_data, family=binomial(link="logit"),
                      control = list(maxit = 50))
summary(bc_model_step5) 

bc_model_step6 <- glm(diagnosis ~ compactness_mean,
                      data = bc_data, family=binomial(link="logit"),
                      control = list(maxit = 50))
summary(bc_model_step6) 

bc_model_step7 <- glm(diagnosis ~ concavity_mean,
                      data = bc_data, family=binomial(link="logit"),
                      control = list(maxit = 50))
summary(bc_model_step7) 

bc_model_step8 <- glm(diagnosis ~ concave_points_mean,
                      data = bc_data, family=binomial(link="logit"),
                      control = list(maxit = 50))
summary(bc_model_step8) 

bc_model_step9 <- glm(diagnosis ~ symmetry_mean,
                      data = bc_data, family=binomial(link="logit"),
                      control = list(maxit = 50))
summary(bc_model_step9) 

bc_model_step10 <- glm(diagnosis ~ fractal_dimension_mean,
                      data = bc_data, family=binomial(link="logit"),
                      control = list(maxit = 50))
summary(bc_model_step10) 

bc_model_step11 <- glm(diagnosis ~ radius_se,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step11) 

bc_model_step12 <- glm(diagnosis ~ texture_se,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step12) 

bc_model_step13 <- glm(diagnosis ~ perimeter_se,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step13) 

bc_model_step14 <- glm(diagnosis ~ area_se,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step14) 

bc_model_step15 <- glm(diagnosis ~ smoothness_se,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step15) 

bc_model_step16 <- glm(diagnosis ~ compactness_se,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step16) 

bc_model_step17 <- glm(diagnosis ~ concavity_se,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step17) 

bc_model_step18 <- glm(diagnosis ~ concave_points_se,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step18) 

bc_model_step19 <- glm(diagnosis ~ symmetry_se,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step19) 

bc_model_step20 <- glm(diagnosis ~ fractal_dimension_se,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step20) 

bc_model_step21 <- glm(diagnosis ~ radius_worst,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step21) 

bc_model_step22 <- glm(diagnosis ~ texture_worst,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step22) 

bc_model_step23 <- glm(diagnosis ~ perimeter_worst,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step23) 

bc_model_step24 <- glm(diagnosis ~ area_worst,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step24) 

bc_model_step25 <- glm(diagnosis ~ smoothness_worst,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step25) 

bc_model_step26 <- glm(diagnosis ~ compactness_worst,
                       data = bc_data, family=binomial(link="logit"),
control = list(maxit = 50))

bc_model_step27 <- glm(diagnosis ~ concavity_worst,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step27) 

bc_model_step28 <- glm(diagnosis ~ concave_points_worst,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step28)

bc_model_step29 <- glm(diagnosis ~ symmetry_worst,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step29) 

bc_model_step30 <- glm(diagnosis ~ fractal_dimension_worst,
                       data = bc_data, family=binomial(link="logit"),
                       control = list(maxit = 50))
summary(bc_model_step30) 
```

###Deviance Residual Plots for all Variables Modeled Independently Against Diagnosis 

The deviance residual is useful for determining if individual points are not well fit by the model. The deviance residual for the ith observation is the signed square root of the contribution of the ith case to the sum for the model deviance, DEV .

In standard linear models, we estimate the parameters by minimizing the sum of the squared residuals, equivalent to finding parameters that maximize the likelihood. In a GLM we also fit parameters by maximizing the likelihood and is equivalent to finding parameter values that minimize the deviance.

```{r step_model plots}
#par(mfrow=c(5,6))
plot(residuals(bc_model_step1), main="radius_mean")
plot(residuals(bc_model_step2), main="texture_mean")
plot(residuals(bc_model_step3), main="perimeter_mean")
plot(residuals(bc_model_step4), main="area_mean")
plot(residuals(bc_model_step5), main="smoothness_mean")
plot(residuals(bc_model_step6), main="compactness_mean")
plot(residuals(bc_model_step7), main="concavity_mean")
plot(residuals(bc_model_step8), main="concave_points_mean")
plot(residuals(bc_model_step9), main="symmetry_mean")
plot(residuals(bc_model_step10), main="fractal_dimension_mean")
plot(residuals(bc_model_step11), main="radius_se")
plot(residuals(bc_model_step12), main="texture_se")
plot(residuals(bc_model_step13), main="perimeter_se")
plot(residuals(bc_model_step14), main="area_se")
plot(residuals(bc_model_step15), main="smoothness_se")
plot(residuals(bc_model_step16), main="compactness_se")
plot(residuals(bc_model_step17), main="concavity_se")
plot(residuals(bc_model_step18), main="concave_points_se")
plot(residuals(bc_model_step19), main="symmetry_se")
plot(residuals(bc_model_step20), main="fractal_dimension_se")
plot(residuals(bc_model_step21), main="radius_worst")
plot(residuals(bc_model_step22), main="texture_worst")
plot(residuals(bc_model_step23), main="perimeter_worst")
plot(residuals(bc_model_step24), main="area_worst")
plot(residuals(bc_model_step25), main="smoothness_worst")
plot(residuals(bc_model_step26), main="compactness_worst")
plot(residuals(bc_model_step27), main="concavity_worst")
plot(residuals(bc_model_step28), main="concave_points_worst")
plot(residuals(bc_model_step29), main="symmetry_worst")
plot(residuals(bc_model_step30), main="fractal_dimension_worst")
#par(mfrow=c(1,1))
```

###Methods for Selecting Variables

In order to examine all possible models for these variables, we would have to creat 2^30 different  model combinations which is computationally infeasible. Insteas we must choose a method for model selection taking into account the high correlation between variables.

###Examine the Correlation of the Variables 

Often we have variables that are highly correlated and therefore redundant. By eliminating highly correlated features we can avoid a predictive bias for the information contained in these features. 

```{r cor}
corMatMy <- cor(bc_data[,3:32])
corrplot(corMatMy, order = "hclust", tl.cex = 0.7)
```

```{r highcor, include=FALSE}
highlyCor <- colnames(bc_data[,3:32])[findCorrelation(corMatMy, cutoff = 0.7, verbose = TRUE)]
```

#####These are the variables that are highly correlated:

```{r print cor vars}
highlyCor
```

Correlations between all features are calculated and visualised with the corrplot package. We could consider removing all features with a correlation higher than 0.7 as a means of variable selection. But for now let's explore other options for variable selection.


####AIC - Akaike Information Criterion

Akaike information criterion (AIC) is a fined technique based on in-sample fit to estimate the likelihood of a model to predict/estimate the future values. A good model is the one that has minimum AIC among all the other models. Bayesian information criterion (BIC) is another criteria for model selection that measures the trade-off between model fit and complexity of the model. A lower AIC or BIC value indicates a better fit. Given a collection of models for the data, AIC estimates the quality of each model, relative to each of the other models. Thus, AIC provides a means for model selection.

AIC basic principles:

 - Lower indicates a more parsimonious model, relative to a model fit
with a higher AIC.

 - It is a relative measure of model parsimony, so it only has
meaning if we compare the AIC for alternate hypotheses (= different
models of the data).

 - The comparisons are only valid for models that are fit to the same response
data (ie values of y).

 - You shouldn’t compare too many models with the AIC. You will run
into the same problems with multiple model comparison as you would
with p-values, in that you might by chance find a model with the
lowest AIC, that isn’t truly the most appropriate model.

 - When using the AIC you might end up with multiple models that
perform similarly to each other. So you have similar evidence
weights for different alternate hypotheses. 

Let's take a look at AIC for each variable modeled independently against diagnosis.

####Table of AIC for All Variables Modeled Independently against Diagnosis 

                 Variable    |      AIC
    ------------------------ | ----------------------
                 radius_mean | `r bc_model_step1$aic`
                texture_mean | `r bc_model_step2$aic`   
              perimeter_mean | `r bc_model_step3$aic`
                   area_mean | `r bc_model_step4$aic`
             smoothness_mean | `r bc_model_step5$aic`
            compactness_mean | `r bc_model_step6$aic`
              concavity_mean | `r bc_model_step7$aic`    
         concave_points_mean | `r bc_model_step8$aic`
               symmetry_mean | `r bc_model_step9$aic`
      fractal_dimension_mean | `r bc_model_step10$aic`
                   radius_se | `r bc_model_step11$aic`
                  texture_se | `r bc_model_step12$aic`
                perimeter_se | `r bc_model_step13$aic`
                     area_se | `r bc_model_step14$aic`
               smoothness_se | `r bc_model_step15$aic`
              compactness_se | `r bc_model_step16$aic` 
                concavity_se | `r bc_model_step17$aic`       
           concave_points_se | `r bc_model_step18$aic`
                 symmetry_se | `r bc_model_step19$aic` 
        fractal_dimension_se | `r bc_model_step20$aic`
                radius_worst | `r bc_model_step21$aic`
               texture_worst | `r bc_model_step22$aic` 
             perimeter_worst | `r bc_model_step23$aic` 
                  area_worst | `r bc_model_step24$aic`
            smoothness_worst | `r bc_model_step25$aic` 
           compactness_worst | `r bc_model_step26$aic`
             concavity_worst | `r bc_model_step27$aic`      
        concave_points_worst | `r bc_model_step28$aic`
              symmetry_worst | `r bc_model_step29$aic` 
     fractal_dimension_worst | `r bc_model_step30$aic`
                          


### Genetic Algorithm

A genetic algorithm is a search heuristic that is inspired by Charles Darwin’s theory of natural evolution. The genetic algorithm is a method for solving both constrained and unconstrained optimization problems that is based on natural selection, the process that drives biological evolution. The genetic algorithm repeatedly modifies a population of individual solutions.

Using a genetic algorith to select the variables which best predict a benign or malignant outcome:
 
```{r genetic glm, include=FALSE}
#rearranging the variables for model input
bc_data_no_id <- bc_data %>% select(-id) %>%
  mutate(diagnosis_b=ifelse(diagnosis=="B",0,1)) %>%
  select(-diagnosis)

bc_data_test <- bc_data_test %>% select(-id) %>%
 mutate(diagnosis_b=ifelse(diagnosis=="B",0,1)) %>%
 select(-diagnosis)

#model with predictors selected after many models examined to find the consistently chosen by stepwise AIC
glmulti.logistic.out <-
 glmulti(diagnosis_b ~ radius_mean + perimeter_mean + compactness_mean + concavity_mean + 
             symmetry_mean + concave_points_mean + radius_se + area_se + concave_points_se + 
             concavity_se + fractal_dimension_se + texture_worst + area_worst + symmetry_worst + 
             fractal_dimension_worst, 
            data = bc_data_no_id,
          level = 1,               # No interaction considered
          method = "g",            # Genetic algorithms search
          crit = "aic",            # AIC as criteria
          confsetsize = 20,        # Keep 20 best models
          plotty = F, report = T,  # No plot or interim reports
          fitfunction = "glm",     # glm function
          family = binomial,       # binomial family for logistic regression
          includeobjects = T )
```

Using a genetic algorithm, multiple models were computed to select the variables which most often appeared in the models generated. I chose the 15 variables which repeatedly were selected by the algorithm to create the final model below.

###Summary and Plots of Final Model Selected

```{r plots of final model}

## Show 5 best models (Use @ instead of $ for an S4 object)
summary(glmulti.logistic.out@objects[[1]])

plot(glmulti.logistic.out, type="p")
plot(glmulti.logistic.out, type="s")
plot(glmulti.logistic.out, type="w")
print(glmulti.logistic.out)

plot(residuals(glmulti.logistic.out@objects[[1]]))
```

###Linearity Assumption Check

```{r linearity assumption check}
predictors <- c("perimeter_mean","compactness_mean","concavity_mean", 
    "symmetry_mean","area_se","concave_points_se","concavity_se",
    "fractal_dimension_se","texture_worst","area_worst","symmetry_worst",
    "fractal_dimension_worst")
probabilities <- predict.glm(glmulti.logistic.out@objects[[1]], type="response")
predicted.classes <- ifelse(probabilities <= 0.5, 0, 1)
# bind the logit and tidy the data
bc_data_logits <- bc_data %>%
    select(-id, -diagnosis) %>%
    select(predictors) %>%
    mutate(logit = log(probabilities/(1-probabilities))) %>%
    gather(key="predictor", value="predictor.value", -logit)

ggplot(bc_data_logits, aes(logit, predictor.value)) +
    geom_point(size=0.5, alpha=0.5) +
    geom_smooth(method="loess") +
    theme_minimal() +
    facet_wrap(~predictor, scales="free_y")
```

We can see that the variables are all linearly related to the logit(pi) if all other predictors are held constant this meeting the first condition for linear regression.

###Model Probability

```{r model prob}
### predictor probabilities for final model validation on the test set
predictions <- predict.glm(glmulti.logistic.out@objects[[1]], newdata=bc_data_test, type="response")
xtab <- table( ifelse(predictions <= 0.5, 0, 1), bc_data_test$diagnosis_b)
caret::confusionMatrix(xtab)

```

Final test of model validation is done by making predictions on a sample of data
not used in the model building work; this is the hold-out or test set.  The model
is used to predict probabilities of the hold-outs observations being malignant.  A threshold
is chosen where probabilities above 0.5 are classified as malignant and benign otherwise.
These predicted classifications are compared against actuals value using a confusion matrix
and several measures of model performance, such as sensitivity (proportion of actual
positives that are correctly identified) and specificity (propotion of actual negatives
that are correctly identified).

###Hypothesis Test 

For our final model validation we conclude the hypothesis test by calculating the output and the p-value comparing the full model to the null model.

```{r hypothesis test}
nmod <- glm(diagnosis_b~1, family="binomial", data=bc_data_no_id)
anova(nmod, glmulti.logistic.out@objects[[1]], test="Chisq")
```

We can see that the probability is nearly zero and we therefore reject the null hypothesis.

###Brief description of methodology that reflects your conceptual understanding

- Identified and collected a dataset to perform analysis
- Split the data into model build and hold-out (i.e., test) sets.  
- Retain the test set as a final check on model performance.
- Exploratory analysis
- Identify independent (predictor) variable correlations
- Perform model selection using univariate predictor selection
- Perform model selection using stepwise predictor selection
- Perform model selection using genetic algorithms, a heuristic approach to model selection
- Compare multiple model selection approaches, synthesizing a single model from all prior approaches
- Validate model compared to null model (hypothesis)
- Check final model performance on hold-out data set

## Part 5 - Conclusion

In rejecting the null hypothesis, we found that a combination of variables predicted the diagnosis to within 96.5% accuracy. We also found that many of the variables are highly correlated, making variable selection important. A lack of domain knowledge made feature selection more difficult as well. I also learned that modeling with 30 variables is more challenging than expected.

### References

This database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog/cpo-dataset/machine-learn/WDBC/

Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29

Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.

Creators: 

1. Dr. William H. Wolberg, General Surgery Dept. 
University of Wisconsin, Clinical Sciences Center 
Madison, WI 53792 
wolberg '@' eagle.surgery.wisc.edu 

2. W. Nick Street, Computer Sciences Dept. 
University of Wisconsin, 1210 West Dayton St., Madison, WI 53706 
street '@' cs.wisc.edu 608-262-6619 

3. Olvi L. Mangasarian, Computer Sciences Dept. 
University of Wisconsin, 1210 West Dayton St., Madison, WI 53706 
olvi '@' cs.wisc.edu 

W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993.

O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.

W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) 163-171.

W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Image analysis and machine learning applied to breast cancer diagnosis and prognosis. Analytical and Quantitative Cytology and Histology, Vol. 17 No. 2, pages 77-87, April 1995.

W.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. Computerized breast cancer diagnosis and prognosis from fine needle aspirates. Archives of Surgery 1995;130:511-516.

W.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. Computer-derived nuclear features distinguish malignant from benign breast cytology. Human Pathology, 26:792–796, 1995.
